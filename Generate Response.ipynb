{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "315a0354",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/saramf/anaconda3/envs/gpt/lib/python3.10/importlib/__init__.py:126: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
      "\n",
      "For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\n",
      "with: `from pydantic import BaseModel`\n",
      "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
      "\n",
      "  return _bootstrap._gcd_import(name[level:], package, level)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.schema import Document\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd4186a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings_file_name(tool=\"llamaparse\", company_name=\"LOREAL_2023\", chunking_method_name=\"chunk-pages\",embedding_model_name=\"text-embedding-3-large\"):\n",
    "    return f\"04-embeddings/{company_name}_chroma_db_ocr-{tool}_{chunking_method_name}_{embedding_model_name}\"\n",
    "\n",
    "    \n",
    "\n",
    "def get_db_from_file(file, embeddings_model):\n",
    "    db = Chroma(persist_directory=file, embedding_function=embeddings_model)\n",
    "    return db\n",
    "\n",
    "\n",
    "def get_all_docs_from_db(db):\n",
    "    all_docs = db.get(include=[\"documents\", \"metadatas\"])\n",
    "    \n",
    "    documents = all_docs[\"documents\"]\n",
    "    metadatas = all_docs[\"metadatas\"]\n",
    "\n",
    "    \n",
    "    if \"metadatas\" in all_docs:\n",
    "        if (all_docs[\"metadatas\"] == [None] * len(all_docs[\"metadatas\"])):\n",
    "        \n",
    "            \n",
    "            doc_objects = [Document(page_content=doc, metadata={'type':\"text\"}) for doc in documents ]\n",
    "\n",
    "        \n",
    "        else:\n",
    "            doc_objects=[]\n",
    "            for doc, meta in zip(documents, metadatas):\n",
    "                if meta:\n",
    "                    doc_objects.append(Document(page_content=doc, metadata=meta))\n",
    "                else:\n",
    "                    doc_objects.append(Document(page_content=doc, metadata={'type':\"text\"}))\n",
    "    else:\n",
    "        doc_objects = [Document(page_content=doc, metadata={'type':\"text\"}) for doc in documents ]\n",
    "    \n",
    "    return doc_objects\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_vector_retriever(query, retriever,k=8):\n",
    "    vector_results = retriever.get_relevant_documents(query)\n",
    "    \n",
    "    unique_results = {doc.page_content: doc for doc in vector_results}\n",
    "    \n",
    "    return list(unique_results.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "965b0b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "company_name=\"LOREAL_2023\" \n",
    "model=\"llm2_gpt-4o\"\n",
    "tool=\"llm2_gpt-4o\" \n",
    "chunking_method_name=\"chunk-pages\" # \"chunk-pages\" \"chunk-markdown\" \"chunk-recursive\"\n",
    "embedding_model_name=\"embeddings-multilingual-e5-large-instruct\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff336363",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/saramf/anaconda3/envs/gpt/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/saramf/anaconda3/envs/gpt/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "embeddings_model = HuggingFaceEmbeddings(model_name=\"intfloat/multilingual-e5-large-instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd759f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_k=8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ef7f028",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_file_name=get_embeddings_file_name(\n",
    "                                        company_name=company_name, \n",
    "                                     tool=tool, \n",
    "                                     chunking_method_name=chunking_method_name,\n",
    "                                     embedding_model_name=embedding_model_name)\n",
    "\n",
    "db = get_db_from_file(emb_file_name,embeddings_model=embeddings_model)\n",
    "\n",
    "splits=get_all_docs_from_db(db)\n",
    "\n",
    "\n",
    "vector_retriever = db.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": top_k})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "14b6ae03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_results_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5c84f2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_24181/3612113718.py:41: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  vector_results = retriever.get_relevant_documents(query)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: \n",
      "\n",
      "Quelles sont les entités ou personnes qui composent l'actionnariat de LOREAL ?\n",
      "\n",
      "\n",
      "Réponse lLLM: Au 31 décembre 2023, l'actionnariat de L'Oréal se compose des entités et personnes suivantes :\n",
      "\n",
      "- **34,73 %** : Mme Françoise Bettencourt Meyers et sa famille, comprenant MM. Jean-Pierre Meyers, Jean-Victor Meyers et Nicolas Meyers, ainsi que les sociétés Téthys SAS et Financière L’Arcouest SAS.\n",
      "- **30,7 %** : Nestlé S.A.\n",
      "- **20,13 %** : Institutionnels internationaux.\n",
      "- **6,63 %** : Institutionnels français.\n",
      "- **5,92 %** : Actionnaires individuels.\n",
      "- **1,89 %** : Salariés (incluant les anciens salariés).\n",
      "\n",
      "Ceux qui agissent de concert sont principalement la famille Bettencourt Meyers et Nestlé, qui ne sont plus en accord depuis le 21 mars 2018.\n"
     ]
    }
   ],
   "source": [
    "question = '''\n",
    "\n",
    "Quelles sont les entités ou personnes qui composent l'actionnariat de LOREAL ?\n",
    "'''\n",
    "contexte=get_vector_retriever(question, vector_retriever,k=top_k)\n",
    "query_results_text = \"\\n-- \".join([x.page_content for x in contexte])\n",
    "\n",
    "client = OpenAI()\n",
    "reponse=client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are an expert in gathering information from annual reports.\"},\n",
    "            {\"role\": \"user\", \"content\": f\"Answer diligently on this question {question} from the following texts of the report:\"},\n",
    "            {\"role\": \"user\", \"content\": f\"{query_results_text}\"},\n",
    "            {\"role\": \"user\", \"content\": f\"Be concise and provide the most relevant information from the texts only. Do not use the internet or general knowledge.\"},\n",
    "        ]\n",
    "        ).choices[0].message.content\n",
    "\n",
    "\n",
    "print(f\"Question: {question}\")\n",
    "print(f\"\\nRéponse lLLM: {reponse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f54ded2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
