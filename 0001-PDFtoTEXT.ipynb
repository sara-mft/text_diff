{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "955583ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import io\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "\n",
    "cwd = os.getcwd()\n",
    "current_dir=os.getcwd()\n",
    "parrent_dir=os.path.abspath(os.path.join(cwd, os.pardir))\n",
    "sys.path.insert(1, current_dir+'/01-scripts')\n",
    "\n",
    "\n",
    "import src_pdftojson as pdftojson\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e723527",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6458d6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51495ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "azure_doc_endpoint = \"\"\n",
    "azure_doc_key = (\"\")\n",
    "\n",
    "os.environ[\"LLAMA_CLOUD_API_KEY\"] =\"\"\n",
    "\n",
    "azure_llm_endpoint=\"\"\n",
    "azure_llm_api_key=\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90b069f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "company_name=\"SANOFI\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a214a7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_sample_documents = \"00-data/pdf_inputs/\"+company_name+\"_2024_test.pdf\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070eedb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "company_name=\"SANOFI\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eaf767d",
   "metadata": {},
   "outputs": [],
   "source": [
    "companies=[\"Stellantis_2023\",\"LOREAL_2023\",\"totalenergies_2023\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f11843",
   "metadata": {},
   "outputs": [],
   "source": [
    "for company_name in companies:\n",
    "    path_to_sample_documents = \"00-data/pdf_inputs/\"+company_name+\".pdf\"\n",
    "\n",
    "    #PyPDF\n",
    "    print(\"**********************************************\")\n",
    "    print(company_name+\" : PyPDF\")\n",
    "    output_txt_file_name=\"00-data/text_outputs/\"+company_name+\"_pypdf.json\"\n",
    "    pdftojson.pdf_to_json_pypdf(path_to_sample_documents, output_txt_file_name)\n",
    "\n",
    "    #PyMuPdf\n",
    "    print(\"**********************************************\")\n",
    "    print(company_name+\" : PyMuPDF\")\n",
    "    output_txt_file_name=\"00-data/text_outputs/\"+company_name+\"_pymupdf.json\"\n",
    "    pdftojson.extract_text_with_pymupdf_to_json(path_to_sample_documents, output_txt_file_name)\n",
    "\n",
    "    #Azure\n",
    "    print(\"**********************************************\")\n",
    "    print(company_name+\" : Azure Intelligence\")\n",
    "\n",
    "    output_txt_file_name=\"00-data/text_outputs/\"+company_name+\"_azure.json\"\n",
    "    pdftojson.pdf_to_json_azure(path_to_sample_documents, output_txt_file_name, azure_doc_key, azure_doc_endpoint)\n",
    "\n",
    "    #LLamaParse\n",
    "    print(\"**********************************************\")\n",
    "    print(company_name+\" : LLamaParse\")\n",
    "    \n",
    "    output_txt_file_name=\"00-data/text_outputs/\"+company_name+\"_llamaparse.json\"\n",
    "    pdftojson.extract_text_from_pdf_llamaparse_json(\n",
    "        pdf_path=path_to_sample_documents,\n",
    "        json_output_path=output_txt_file_name,\n",
    "        parse_mode = \"parse_page_with_lvm\",\n",
    "        vendor_model = \"openai-gpt4o\",\n",
    "        verbose=True\n",
    "    )\n",
    "\n",
    "    #Extract pages as images + LLM\n",
    "    print(\"**********************************************\")\n",
    "    print(company_name+\" : Extract pages as images + LLM\")\n",
    "    markdown_prompt = \"\"\"Analyze the content and structure of this page image.\n",
    "    Extract all text and format it using Markdown syntax.\n",
    "    Key formatting instructions:\n",
    "    - Use Markdown headings (#, ##, ###, etc.) for titles and section headers.\n",
    "    - Use bullet points (-) or numbered lists (1., 2.) for lists.\n",
    "    - Preserve paragraph breaks.\n",
    "    - Use *italic* or _italic_ for italics and **bold** or __bold__ for bold text if clearly distinguishable.\n",
    "    - Represent tables using Markdown table syntax if possible, otherwise extract the content linearly.\n",
    "    - Each Markdown table should start with ### BEGIN TABLE and end with ### END TABLE\n",
    "    - Return only the markdown with no explanation text. Do not include delimiters like \\`\\`\\`markdown or \\`\\`\\`html.\n",
    "\n",
    "    Focus on capturing the semantic structure and content accurately in Markdown format.\"\"\"\n",
    "\n",
    "    LLMs_to_test=[\"gpt-4o\",\"mistral-small-2503\",\"Llama-3.2-90B-Vision-Instruct\",\"Phi-4-multimodal-instruct\"]\n",
    "\n",
    "    for llm in LLMs_to_test:\n",
    "        print(\"**********************************************\")\n",
    "        print(company_name+\" : Extract pages as images + LLM ==> \"+llm)\n",
    "        output_txt_file_name=\"00-data/text_outputs/\"+company_name+\"_llm2_\"+llm+\".json\"\n",
    "\n",
    "        pdftojson.extract_text_from_pdf_azure_vision_json(\n",
    "                pdf_path=path_to_sample_documents,\n",
    "                json_output_path=output_txt_file_name,\n",
    "                prompt=markdown_prompt,\n",
    "                azure_endpoint=azure_llm_endpoint,\n",
    "                azure_api_key=\"\",\n",
    "                azure_model_name=llm,\n",
    "                verbose=True\n",
    "\n",
    "            #\"DeepSeek-V3\"\n",
    "            #Phi-4\n",
    "            #\"Llama-3.3-70B-Instruct\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d124cdb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a151c9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f515b6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b45b06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9349f371",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f3a641",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "940d5bc5",
   "metadata": {},
   "source": [
    "# Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29eb4fc2",
   "metadata": {},
   "source": [
    "## PyPDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf2db8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_txt_file_name=\"00-data/text_outputs/\"+company_name+\"_2024_test_pypdf.json\"\n",
    "pdftojson.pdf_to_json_pypdf(path_to_sample_documents, output_txt_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef47f294",
   "metadata": {},
   "source": [
    "## PyMuPdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3b0d53e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Text extracted and saved to JSON: 00-data/text_outputs/SANOFI_2024_test_pymupdf.json\n"
     ]
    }
   ],
   "source": [
    "output_txt_file_name=\"00-data/text_outputs/\"+company_name+\"_2024_test_pymupdf.json\"\n",
    "pdftojson.extract_text_with_pymupdf_to_json(path_to_sample_documents, output_txt_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01751db6",
   "metadata": {},
   "source": [
    "## Azure Document Intelligence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09b713f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "azure_endpoint = \"\"\n",
    "azure_key = (\"\")\n",
    "\n",
    "output_txt_file_name=\"00-data/text_outputs/\"+company_name+\"_2024_test_azure.json\"\n",
    "pdftojson.pdf_to_json_azure(path_to_sample_documents, output_txt_file_name, azure_key, azure_endpoint)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68175594",
   "metadata": {},
   "source": [
    "## Extract tables and graphs as images + LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa2c0505",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] =\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81e4ac05",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_prompt = \"\"\"Analyze the provided image and identify its content (text, table, chart, or other). Then rephrase (in the same language as the text in the image) the information in the most appropriate way:\n",
    "\n",
    "- If the image mainly contains text, present it as well-structured paragraphs.\n",
    "- If the image contains a table, format it in Markdown while preserving its structure and content, followed by a summary of the table's contents.\n",
    "- If the image contains a chart, describe all the information from the chart in bullet points.\n",
    "- If the image contains a combination of these elements, adapt the format accordingly.\n",
    "- If the image contains a blurry element, a logo, or photos of people,\n",
    "- Do not start with an introductory phrase like “Here is a rephrasing...”.\n",
    "- Do not add any title before, within, or after the table or chart.\n",
    "\n",
    "Ensure that the result is clear, well-organized, and faithful to the original content of the image.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a29b88cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fr_prompt = \"\"\"Analyse l’image fournie et identifie son contenu (texte, tableau, graphique ou autre). Reformule ensuite (dans la même langue que celle du texte présent dans l’image) les informations de la manière la plus appropriée :\n",
    "\n",
    "- Si l’image contient principalement du texte, présente-le sous forme de paragraphes bien structurés.\n",
    "- Si l’image contient un tableau, reformate-le en Markdown en préservant sa structure et son contenu, suivi d’un résumé du contenu du tableau.\n",
    "- Si l’image contient un graphique, décris toutes les informations du graphique sous forme de points clés.\n",
    "- Si l’image contient une combinaison de ces éléments, adapte le format en conséquence.\n",
    "- Si l’image contient un élément flou, un logo ou des photos de personnes,\n",
    "- Ne commence pas par une phrase d’introduction du type “Voici une reformulation...”.\n",
    "- N’ajoute aucun titre avant, dans ou après le tableau ou le graphique.\n",
    "\n",
    "Assure-toi que le résultat soit clair, bien organisé et fidèle au contenu original de l’image.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9bb1acdb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'company_name' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_5882/3705216143.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0moutput_txt_file_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"00-data/text_outputs/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mcompany_name\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"_2024_test_llm1_Phi-4.json\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m pdftojson.pdf_to_json_LLM_11(\n\u001b[1;32m      4\u001b[0m     \u001b[0mpath_to_sample_documents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath_to_sample_documents\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0moutput_json_file_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_txt_file_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'company_name' is not defined"
     ]
    }
   ],
   "source": [
    "output_txt_file_name=\"00-data/text_outputs/\"+company_name+\"_2024_test_llm1_Phi-4.json\"\n",
    "\n",
    "pdftojson.pdf_to_json_LLM_11(\n",
    "    path_to_sample_documents=path_to_sample_documents,\n",
    "    output_json_file_name=output_txt_file_name,\n",
    "    prompt=en_prompt,\n",
    "    use_azure=True,\n",
    "    azure_endpoint=\"\",\n",
    "    azure_api_key=\"\",\n",
    "    azure_model_name=\"Phi-4\"\n",
    "    #\"Mistral-small\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5803a9b4",
   "metadata": {},
   "source": [
    "## Extract pages as images + LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4466b60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "markdown_prompt = \"\"\"Analyze the content and structure of this page image.\n",
    "Extract all text and format it using Markdown syntax.\n",
    "Key formatting instructions:\n",
    "- Use Markdown headings (#, ##, ###, etc.) for titles and section headers.\n",
    "- Use bullet points (-) or numbered lists (1., 2.) for lists.\n",
    "- Preserve paragraph breaks.\n",
    "- Use *italic* or _italic_ for italics and **bold** or __bold__ for bold text if clearly distinguishable.\n",
    "- Represent tables using Markdown table syntax if possible, otherwise extract the content linearly.\n",
    "- Each Markdown table should start with ### BEGIN TABLE and end with ### END TABLE\n",
    "- Return only the markdown with no explanation text. Do not include delimiters like \\`\\`\\`markdown or \\`\\`\\`html.\n",
    "\n",
    "Focus on capturing the semantic structure and content accurately in Markdown format.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "296b66c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "markdown_prompt_fr = \"\"\"Analyse le contenu et la structure de cette image de page.\n",
    "Extrait tout le texte et formate-le en utilisant la syntaxe Markdown.\n",
    "Instructions de formatage clés :\n",
    "- Utilise les titres Markdown (#, ##, ###, etc.) pour les titres et les en-têtes de section.\n",
    "- Utilise des listes à puces (-) ou des listes numérotées (1., 2.) pour les listes.\n",
    "- Préserve les sauts de paragraphe.\n",
    "- Utilise *italique* ou _italique_ pour l’italique et **gras** ou __gras__ pour le texte en gras si c’est clairement identifiable.\n",
    "- Représente les tableaux en utilisant la syntaxe Markdown pour les tableaux si possible, sinon extrais le contenu de manière linéaire.\n",
    "- Chaque tableau en Markdown doit commencer par ### BEGIN TABLE et se terminer par ### END TABLE\n",
    "- Ne retourne que le Markdown sans texte explicatif. N’inclus pas de délimiteurs comme \\`\\`\\`markdown ou \\`\\`\\`html.\n",
    "\n",
    "Concentre-toi sur la capture précise de la structure sémantique et du contenu en format Markdown.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1d8046ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_txt_file_name=\"00-data/text_outputs/\"+company_name+\"_2024_test_llm22.json\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da54b254",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "pdftojson.extract_text_from_pdf_gpt4o_json(\n",
    "        pdf_path=path_to_sample_documents,\n",
    "        json_output_path=output_txt_file_name,\n",
    "        prompt=markdown_prompt,\n",
    "        verbose=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd22782",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output_txt_file_name=\"00-data/text_outputs/\"+company_name+\"_2024_test_llm2_mistral-small-2503-2.txt\"\n",
    "\n",
    "pdftojson.extract_text_from_pdf_azure_vision_json(\n",
    "        pdf_path=path_to_sample_documents,\n",
    "        json_output_path=output_txt_file_name,\n",
    "        prompt=markdown_prompt,\n",
    "    \n",
    "        azure_endpoint=\"\",\n",
    "        azure_api_key=\"\",\n",
    "    \n",
    "        azure_model_name=\"mistral-small-2503-2\",\n",
    "        verbose=True\n",
    "    #Phi-4\n",
    "    #\"Llama-3.3-70B-Instruct\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6899e711",
   "metadata": {},
   "source": [
    "## LLAMAPARSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddea1e96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
