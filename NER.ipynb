{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b2a2f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin, urlparse\n",
    "from collections import deque\n",
    "import base64\n",
    "import os\n",
    "import logging\n",
    "\n",
    "import openai\n",
    "import json\n",
    "import time\n",
    "from pathlib import Path\n",
    "from html import escape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc18b394",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_bio_dataset(filepath):\n",
    "    \"\"\"\n",
    "    Load sentences and labels from a BIO-formatted file.\n",
    "    Returns a list of sentences, where each sentence is a list of tokens,\n",
    "    and a parallel list of labels.\n",
    "    \"\"\"\n",
    "    sentences, labels = [], []\n",
    "    _, tokens, tags = [], [], []\n",
    "\n",
    "    with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:  # Sentence boundary\n",
    "                if tokens:\n",
    "                    sentences.append(tokens)\n",
    "                    labels.append(tags)\n",
    "                    _, tokens, tags = [], [], []\n",
    "                continue\n",
    "            parts = line.split()\n",
    "            if len(parts) < 3:\n",
    "                continue\n",
    "            token, tag = parts[1], parts[-1]\n",
    "            tokens.append(token)\n",
    "            tags.append(tag)\n",
    "\n",
    "    # Add last sentence if file doesn't end with newline\n",
    "    if tokens:\n",
    "        sentences.append(tokens)\n",
    "        labels.append(tags)\n",
    "\n",
    "    return sentences, labels\n",
    "\n",
    "\n",
    "\n",
    "filepath = \"test.conllu\"  # path to your dataset\n",
    "sentences, labels = load_bio_dataset(filepath)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5324cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3e2554d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from sklearn.metrics import classification_report\n",
    "import re\n",
    "\n",
    "def clean_llm_output(output: str) -> str:\n",
    "    \"\"\"\n",
    "    Extracts the first valid JSON array from an LLM response.\n",
    "    \"\"\"\n",
    "    # Remove code fences if present\n",
    "    output = re.sub(r\"```(json)?\", \"\", output).strip()\n",
    "    \n",
    "    # Find JSON array with regex\n",
    "    match = re.search(r\"\\[.*\\]\", output, re.DOTALL)\n",
    "    if match:\n",
    "        return match.group(0)\n",
    "    else:\n",
    "        raise ValueError(\"No valid JSON array found in output.\")\n",
    "\n",
    "\n",
    "\n",
    "def parse_llm_output(llm_json_str):\n",
    "    \"\"\"\n",
    "    Parse LLM output JSON into a list of labels.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        parsed = json.loads(llm_json_str)\n",
    "        return [item[\"label\"] for item in parsed]\n",
    "    except Exception as e:\n",
    "        print(\"Error parsing JSON:\", e)\n",
    "        return []\n",
    "\n",
    "def evaluate_predictions(gold_labels, pred_labels):\n",
    "    \"\"\"\n",
    "    Evaluate BIO predictions with precision, recall, F1.\n",
    "    \"\"\"\n",
    "    # Flatten sequences for token-level evaluation\n",
    "    gold_flat = [tag for seq in gold_labels for tag in seq]\n",
    "    pred_flat = [tag for seq in pred_labels for tag in seq]\n",
    "\n",
    "    print(classification_report(gold_flat, pred_flat, digits=4))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8aaecbb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Mock LLM outputs ---\n",
    "# In practice, replace this with actual calls to your LLM\n",
    "llm_outputs = []\n",
    "for sent in sentences[:5]:  # only first 5 sentences for testing\n",
    "    \n",
    "    fake_json = json.dumps([{\"token\": tok, \"label\": \"O\"} for tok in sent])\n",
    "    llm_outputs.append(fake_json)\n",
    "\n",
    "# Parse predictions\n",
    "pred_labels = [parse_llm_output(out) for out in llm_outputs]\n",
    "\n",
    "# Evaluate\n",
    "evaluate_predictions(gold_labels[:5], pred_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536268e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"test.conllu\"\n",
    "sentences, gold_labels = load_bio_dataset(filepath)\n",
    "\n",
    "llm_outputs = []\n",
    "\n",
    "\n",
    "for sent, gold in zip(sentences[:5],gold_labels[:5]):  # only first 5 sentences for testing\n",
    "    \n",
    "    \n",
    "    \n",
    "    example=[\n",
    "      {\"token\": \"I\", \"label\": \"O\"},\n",
    "      {\"token\": \"need\", \"label\": \"O\"},\n",
    "      {\"token\": \"that\", \"label\": \"O\"},\n",
    "      {\"token\": \"movie\", \"label\": \"O\"},\n",
    "      {\"token\": \"which\", \"label\": \"O\"},\n",
    "      {\"token\": \"involves\", \"label\": \"O\"},\n",
    "      {\"token\": \"aliens\", \"label\": \"O\"},\n",
    "      {\"token\": \"invading\", \"label\": \"O\"},\n",
    "      {\"token\": \"earth\", \"label\": \"O\"},\n",
    "      {\"token\": \"in\", \"label\": \"O\"},\n",
    "      {\"token\": \"a\", \"label\": \"O\"},\n",
    "      {\"token\": \"particular\", \"label\": \"O\"},\n",
    "      {\"token\": \"united\", \"label\": \"B-LOC\"},\n",
    "      {\"token\": \"states\", \"label\": \"I-LOC\"},\n",
    "      {\"token\": \"place\", \"label\": \"O\"},\n",
    "      {\"token\": \"in\", \"label\": \"O\"},\n",
    "      {\"token\": \"california\", \"label\": \"B-LOC\"}\n",
    "    ]\n",
    "    \n",
    "    \n",
    "    list_tokens=[tok for tok in sent]\n",
    "    \n",
    "    input_text= f\"{list_tokens}\"\n",
    "\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    ### Instructions:\n",
    "    1. Each sentence is alrealdy tokenized.\n",
    "    2. Assign each token a label in **BIO format**:\n",
    "       - **B-<ENTITY>** → the first token of a named entity\n",
    "       - **I-<ENTITY>** → a subsequent token inside the same entity\n",
    "       - **O** → a token not part of any entity\n",
    "    3. Use the following entity types: **PER (for person), ORG (for organization), LOC (for location)**.\n",
    "    4. Output the result in **JSON format** as an array of objects, where each object has:\n",
    "       - `\"token\"` → the token text\n",
    "       - `\"label\"` → the BIO label\n",
    "\n",
    "    ### Example Input:\n",
    "\n",
    "    ```json\n",
    "    {example}\n",
    "    ```\n",
    "\n",
    "    Perform BIO tagging for the following text:  \n",
    "    **[{input_text}]**\n",
    "\n",
    "    Important: Return **only valid JSON** in the format shown above.  \n",
    "    Do not include explanations, comments, or any text outside of the JSON array.\n",
    "\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    payload = {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": \"You are an expert in LLMs, prompt engineering, and AI. Your task is to perform **Named Entity Recognition (NER)** using the **BIO tagging scheme**.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        \"temperature\": 0.0\n",
    "    }\n",
    "\n",
    "    response = requests.post(MODEL_URL, headers=HEADERS, json=payload)\n",
    "    response.raise_for_status()\n",
    "\n",
    "\n",
    "    llm_outputs.append(response.json()[\"choices\"][0][\"message\"][\"content\"])\n",
    "\n",
    "# Parse predictions\n",
    "\n",
    "pred_labels = [parse_llm_output(clean_llm_output(out)) for out in llm_outputs]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9eca03",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=evaluate_predictions(gold_labels[:5], pred_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc06c899",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
